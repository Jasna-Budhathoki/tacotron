
-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2022-06-15 05:48:20.573]  Checkpoint path: ./logs-tacotron/model.ckpt
[2022-06-15 05:48:20.573]  Loading training data from: /usr/src/app/tacotron/training/train.txt
[2022-06-15 05:48:20.573]  Using model: tacotron
[2022-06-15 05:48:20.574]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: transliteration_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: False

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2022-06-15 05:53:03.235]  Checkpoint path: ./logs-tacotron/model.ckpt
[2022-06-15 05:53:03.235]  Loading training data from: /usr/src/app/tacotron/training/train.txt
[2022-06-15 05:53:03.235]  Using model: tacotron
[2022-06-15 05:53:03.235]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: transliteration_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: False

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2022-06-15 05:55:34.387]  Checkpoint path: ./logs-tacotron/model.ckpt
[2022-06-15 05:55:34.387]  Loading training data from: /usr/src/app/tacotron/training/train.txt
[2022-06-15 05:55:34.387]  Using model: tacotron
[2022-06-15 05:55:34.387]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: transliteration_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: False
